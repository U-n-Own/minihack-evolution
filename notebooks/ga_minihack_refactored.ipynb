{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import minihack\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import random\n",
    "import math\n",
    "import pygad\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a useful dictionary to define possible actions for the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_dictionary = {\n",
    "    0 : \"north\",\n",
    "    1 : \"east\",\n",
    "    2 : \"south\",\n",
    "    3 : \"west\",\n",
    "    4 : \"north-east\",\n",
    "    5 : \"sud-east\",\n",
    "    6 : \"sud-west\",\n",
    "    7 : \"north-west\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define four functions that we use to extract useful information about the game environment. In particular we will then have:\n",
    "\n",
    "- print_room : takes as input a matrix of integers and prints it in ASCII characters. It is used to visually check the state of the game.\n",
    "\n",
    "- search_environment_indexes : takes as input a matrix of integers and returns the first index of the array other than 32. In creating the task, MiniHack gives us a 21x79 observation matrix, of which we are only interested in its submatrix of size 15x15 that represent the room. All positions outside this submatrix are passed by MiniHack with the value of 32, which in ASCII represents the empty character. This function then allows us to find the 15x15 submatrix that we will work with in the rest of the code.\n",
    "\n",
    "- search_environment_agent_position: takes as input a matrix of integers (the one representing the room in the MiniHack task) and returns the position of the agent inside the room.\n",
    "\n",
    "- search_environment_goal_position: takes as input a matrix of integers (the one representing the room in the MiniHack task) and returns the position of the stairs going down (our goal) inside the room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_room(environment):\n",
    "#Print the room in ASCII characters. \n",
    "    \n",
    "    for row in range(len(environment[:,1])):\n",
    "        for col in range(len(environment[1,:])):\n",
    "            print(chr(environment[row][col]), end=' ') \n",
    "        print('\\n')\n",
    "\n",
    "\n",
    "def search_environment_indexes(environment):\n",
    "#We search the indexes to find the 15x15 submatrix representing the MiniHack task room.\n",
    "\n",
    "    for row in range(len(environment[:,1])):\n",
    "        for col in range(len(environment[1,:])):\n",
    "            if int(environment[row][col]) != 32:\n",
    "                return row, col      \n",
    "\n",
    "\n",
    "def search_environment_agent_position(environment: np.ndarray):\n",
    "    '''\n",
    "    Return agent position inside the environment.\n",
    "    MiniHack passes us the position of the agent in the array with the \n",
    "    value of 64, which in ASCII turns into @.\n",
    "    '''\n",
    "    for row in range(len(environment[:,1])):\n",
    "        for col in range(len(environment[1,:])):\n",
    "            if int(environment[row][col]) == 64:  \n",
    "                return row, col\n",
    "\n",
    "\n",
    "def search_environment_goal_position(environment: np.ndarray):\n",
    "    \"\"\" \n",
    "    Return staircase position inside the environment.\n",
    "    MiniHack passes us the position of the stairs going down in the matrix \n",
    "    with the value of 62, which in ASCII turns into >.\n",
    "    \"\"\"\n",
    "    for row in range(len(environment[:,1])):\n",
    "        for col in range(len(environment[1,:])):\n",
    "            if int(environment[row][col]) == 62:\n",
    "                return row, col\n",
    "\n",
    "def update_position(old_position: List[int], movement: int) -> List[int]:\n",
    "    \"\"\" Return updated positions of the agent in the environment         \n",
    "            old_position is a legal move\n",
    "            movement: int 0..3 indication of direction\n",
    "    \"\"\"\n",
    "\n",
    "    # Directions store the movements possible, if you want to move diagonally you can add more directions here\n",
    "    directions = [(0, -1), (1, 0), (0, 1), (-1, 0), (-1, 1), (1, 1), (1, -1), (-1, -1)] \n",
    "\n",
    "    new_position = [0, 0]\n",
    "\n",
    "    update_position = directions[movement]\n",
    "\n",
    "    # Here we're not checking if goes out of bounds\n",
    "    new_position[0] = old_position[0] + update_position[0]\n",
    "    new_position[1] = old_position[1] + update_position[1]\n",
    "    \n",
    "    return new_position[0], new_position[1] \n",
    "\n",
    "def is_legal_move(old_position: List[int], movement: int) -> bool:\n",
    "    \"\"\" Check if the agent is moving in a legal position \"\"\"\n",
    "\n",
    "    bounds = {\n",
    "        0: (0, -1),\n",
    "        1: (1, 0),\n",
    "        2: (0, 1),\n",
    "        3: (-1, 0),\n",
    "        4: (-1, 1),\n",
    "        5: (1, 1),\n",
    "        6: (1, -1),\n",
    "        7: (-1, -1)\n",
    "        }\n",
    "\n",
    "    new_position = old_position[0] + bounds[movement][0], old_position[1] + bounds[movement][1]\n",
    "    \n",
    "    return new_position[0] in range(15) and new_position[1] in range(15) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class for the random creation of Rules for the MiniHack task. A Rule is constructed to contain the following information:\n",
    "\n",
    "- Position: a pair of randomly created integers indicating a position in a 15x15 matrix.\n",
    "\n",
    "- Movement: an integer between 0 and 7 indicating the movement (following the dictionary defined earlier) that the agent must make when in the above position \n",
    "\n",
    "In the random creation of the Rule, we check its good definition: that is, we check that the movement associated with the position does not cause the agent to go outside the matrix.\n",
    "\n",
    "In the class we also define the rule_list function that takes as input the agent's position seen as two integers and returns the same position seen as a single integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rule:\n",
    "\n",
    "    position: List[int] = [0, 0]\n",
    "    movement: int\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "       \n",
    "        #Initialize a random position\n",
    "        self.position[0] = random.choice(range(0, 15))\n",
    "        self.position[1] = random.choice(range(0, 15))\n",
    "        \n",
    "\n",
    "        #Initialize a random movement\n",
    "        self.movement = random.choice(range(0, 8))\n",
    "        \n",
    "        '''\n",
    "        Check that the Rule is well defined. \n",
    "        after_pos_1 and after_pos_2 are the support \n",
    "        variables indicating the position in the matrix \n",
    "        after applying the movement. \n",
    "        '''\n",
    "        after_pos_1=self.position[0] \n",
    "        after_pos_2=self.position[1]\n",
    "        \n",
    "        old_position = [after_pos_1, after_pos_2]\n",
    "        \n",
    "        after_pos_1, after_pos_2 = update_position(old_position, self.movement)\n",
    "        \n",
    "        \n",
    "        #Check that the position after movement remains in the matrix    \n",
    "        while after_pos_1<0 or after_pos_1>=15 or after_pos_2<0 or after_pos_2>=15:\n",
    "             \n",
    "            self.movement = random.choice(range(0, 7))\n",
    "             \n",
    "            after_pos_1=self.position[0]\n",
    "            after_pos_2=self.position[1]\n",
    "            \n",
    "            old_position = [after_pos_1, after_pos_2]\n",
    "            \n",
    "            after_pos_1, after_pos_2 = update_position(old_position, self.movement)\n",
    "        \n",
    "    def rule_list(self):\n",
    "        return [self.position[0]*15+self.position[1], self.movement]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate MiniHack's Enivornment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the Room Random 15x15 task from MiniHack. In doing so we call in observation_keys the arrays with the information we need in the code. See the MiniHack documentation for more information.  \n",
    "\n",
    "With env.reset() MiniHack generates a new environment (the one on which we will try to solve the task) and we save the room description matrices in the obs variable.\n",
    "\n",
    "With env.render() MiniHack allows us to print the room, and then we see the location of the agent and the location of the staircase, where we would like the agent to go (our goal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make(\n",
    "    \"MiniHack-Room-Random-15x15-v0\",\n",
    "    observation_keys=(\"chars\", \"colors\", \"specials\", \"pixel\"),\n",
    ")\n",
    "\n",
    "obs = env.reset() #Generate a new environment and save the describtions arrays in obs\n",
    "env.render() #Print the room "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the utility functions defined earlier we get the room information of the task we just created.\n",
    "\n",
    "We note that the matrix we print in print_room is the same as the matrix above printed with MiniHack's env.render() command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the indices where the submatrix we are interested in begins\n",
    "i,j = search_environment_indexes(obs['chars'])\n",
    "\n",
    "#print the matrix in ASCII characters. \n",
    "print(\"Tha matrix in ASCII that represent the random room is:\")\n",
    "print_room(obs['chars'][i:i+15, j:j+15])\n",
    "\n",
    "#find the agent position and the goal position in the room    \n",
    "agent_position_1, agent_position_2 = search_environment_agent_position(obs['chars'][i:i+15, j:j+15])\n",
    "goal_1, goal_2 = search_environment_goal_position(obs['chars'][i:i+15, j:j+15])\n",
    "    \n",
    "print(\"The agent position is: \", agent_position_1, \" \",  agent_position_2)\n",
    "print(\"The goal position is: \", goal_1, \" \", goal_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithm for Rule Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Initial Population "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population of our genetic algorithm will be a list of rules. We then initialize the empty list and fill it as we go with new randomly created rules using the Rule class and the rule_list function. \n",
    "\n",
    "Each gene in the population will consist of a pair of integers [x_1, x_2]:\n",
    "\n",
    "- x_1: indicates a position in the matrix (and thus in the room) seen as a subsequence of integers (and not as indices). It is obtained, considering the position described by indices, as follows:\n",
    "\n",
    "                                    x_1 = agent_position_1*15+agent_position_2\n",
    "\n",
    "where agent_position_1 and agent_position_2 are the indices. \n",
    "\n",
    "- x_2: indicates the movement to be made when one is at position x_1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_initial_population=1000 #numbers of genes in the initial population\n",
    "list_of_rules=[]\n",
    "\n",
    "for x in range(num_initial_population):\n",
    "    \n",
    "    rule=Rule()\n",
    "    list_of_rules.append(rule.rule_list())\n",
    "    \n",
    "    #print the initial population.\n",
    "    print(\"The\", x+1, \"-th rules is:\")\n",
    "    #print the position either as an index or as a sequence of integers.\n",
    "    print(\"Position: (\", math.floor(list_of_rules[x][0]/15), \", \", list_of_rules[x][0] % 15, \") =\", list_of_rules[x][0])\n",
    "    #print the movement either as an integer or as a string using dictionary\n",
    "    print(\"Movement: \", list_of_rules[x][1], \" - \", movement_dictionary[list_of_rules[x][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Fitness Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the fitness function for the genetic algorithm.\n",
    "\n",
    "The fitness function must be defined as the pygad documentation requires. The function takes as input solution, which is a gene from the genetic algorithm, and solution_idx, which is the index of the gene in the population. Specifically solution is of the form:\n",
    "\n",
    "- solution[0]: the position in the array written as a sequence of integers\n",
    "\n",
    "- solution[1]: the move to be made at the above position\n",
    "\n",
    "The fitness_function must also return fitness, a numerical value expressing the goodness of the gene (in the specific case, of the rule).\n",
    "\n",
    "In our specific case, our fitness function returns floats between 0 and 100 in the following way:\n",
    "\n",
    "- 0 is returned in several cases. The first case is when the position of the rule coincides with the position of the goal. In fact, when the agent arrives at the goal, the task is declared resolved, and thus there is no need to possess a rule for that position. \n",
    "\n",
    "- 0 is also returned when the movement defined in the gene, applied to the position associated with it, results in the agent leaving the matrix. \n",
    "\n",
    "- If neither of the above cases happens, a numerical value is computed that takes into account two parameters. The first is whether the motion applied to the position causes the agent to approach the goal, move away from it, or remain at the same distance. This parameter is expressed in the numerator of the auxiliar variable. The second parameter takes into account the agent's distance from the goal before performing the action: the farther away the agent is, the less weight the rule will have. This parameter is expressed in the denominator of the auxiliar variable.\n",
    "\n",
    "- The two limiting cases of the previous point are when the agent is at distance 1 from the goal before applying the movement. In this case, if the rule tells the agent to move toward the goal and complete the task, it will assume importance 100. If it moves away from the goal it will instead have importance 0. Finally, if he stays at the same distance it will have non-high importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(solution, solution_idx):\n",
    "     \n",
    "    ag_pos_before_action_1=math.floor(solution[0]/15)\n",
    "    ag_pos_before_action_2=solution[0] % 15\n",
    "    ag_movement=solution[1]\n",
    "\n",
    "    #check that the generated rule is not the goal position\n",
    "    if ag_pos_before_action_1==goal_1 and ag_pos_before_action_2==goal_2:\n",
    "        return 0\n",
    "     \n",
    "    #define the new agent position after applying the action in ag_movement=solution[1]\n",
    "    ag_pos_after_action_1=ag_pos_before_action_1 \n",
    "    ag_pos_after_action_2=ag_pos_before_action_2\n",
    "\n",
    "    old_position = [ag_pos_after_action_1, ag_pos_after_action_2]\n",
    "\n",
    "    ag_pos_after_action_1, ag_pos_after_action_2 = update_position(old_position, ag_movement)\n",
    "    \n",
    "    #check that the new agent position after applying the ag_movement is in the matrix \n",
    "    if ag_pos_after_action_1<0 or ag_pos_after_action_1>=15 or ag_pos_after_action_2<0 or ag_pos_after_action_2>=15:\n",
    "        return 0\n",
    "\n",
    "    #calculate the distance to the goal both before applied the move and after applied the move\n",
    "    distance_before=max(np.abs(ag_pos_before_action_1-goal_1), np.abs(ag_pos_before_action_2-goal_2))\n",
    "    distance_after=max(np.abs(ag_pos_after_action_1-goal_1), np.abs(ag_pos_after_action_2-goal_2))\n",
    "    \n",
    "    #calculate the importance of the rule taking into account the distance to the goal and the goodness of movement\n",
    "    if distance_after!=distance_before: \n",
    "        auxiliar=(distance_before-distance_after)/(math.sqrt(distance_before))\n",
    "    else:\n",
    "        auxiliar=random.randint(-1,1)/(5*math.sqrt(distance_before))\n",
    "        \n",
    "    fitness=50*auxiliar+50\n",
    "\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Pygad Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance of pygad, passing the previously generated list_of_rules as the initial population, and deciding in num_gener the number of iterations of the algorithm. As parent selection we use \"rws,\" which chooses each parent by taking it with a probability obtained by normalizing the fitness value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_func = fitness_function\n",
    "num_gener=10\n",
    "parent_sel = \"rws\"\n",
    "cross_type = \"single_point\"\n",
    "    \n",
    "ga_instance = pygad.GA(fitness_func=fitness_func,\n",
    "                       initial_population=list_of_rules,\n",
    "                       gene_type=int,\n",
    "                       num_generations=num_gener,\n",
    "                       num_parents_mating=num_initial_population,\n",
    "                       parent_selection_type=parent_sel,\n",
    "                       crossover_probability=1.0,\n",
    "                       crossover_type=cross_type,\n",
    "                       mutation_type= None)\n",
    "\n",
    "ga_instance.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save and print the rules generated after the last iteration of the genetic algorithm and their fitness function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_solution=ga_instance.best_solution()[0]\n",
    "final_fitness_value, final_population=ga_instance.last_generation_fitness, ga_instance.last_generation_offspring_mutation\n",
    "\n",
    "print(ga_instance.best_solution()[0])\n",
    "print(final_population)\n",
    "print(final_fitness_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generated Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, using the result of the genetic algorithm, we create a list containing the rules that the agent must follow to complete the task. \n",
    "\n",
    "There can be multiple rules for the same position in the final result of the genetic algorithm. So what we do now is to insert the rules generated by pyagd into the final_rules list, keeping in mind that: for each position there can be a maximum of one rule; and the rule we need to insert is the one with the highest fitness value. Also, if the greatest fitness value is less than 50, we don't insert the rule in the list. \n",
    "\n",
    "To do that, we define an auxiliary list, called auxiliar_rules, in which we insert all the rules present in the final_population with a fitness value greater or equal than 50.\n",
    "\n",
    "We also create a matrix, called environment, that takes into account both the goal position and the positions for which a rule is defined in final_rules. In this way we can print this matrix, marking with a * the positions for which we have a rule, and visually see the distribution of the positions for which we have a rule in the room. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the matrix, initially with only the goal position (46 is the integer that is used to indicate the empty floor)\n",
    "environment=np.full((15, 15), 46, dtype=int)\n",
    "environment[goal_1][goal_2]=62\n",
    "\n",
    "#Define an auxiliar list, with only genes with fitness greater or equal 50\n",
    "ausiliar_rules=[]\n",
    "ausiliar_rules.append([best_solution[0], best_solution[1], final_fitness_value[0]])\n",
    "\n",
    "for x in range(len(final_population)) :\n",
    "    if final_fitness_value[x+1] >=50:\n",
    "        ausiliar_rules.append([final_population[x][0], final_population[x][1], final_fitness_value[x+1]])\n",
    "\n",
    "#Sort the auxiliar list according to descending fitness value \n",
    "ausiliar_rules=sorted(ausiliar_rules, key=itemgetter(2), reverse=True)\n",
    "\n",
    "#Create final_rules, initially empty\n",
    "final_rules=[]\n",
    "\n",
    "for x in range(len(ausiliar_rules)):\n",
    "    axi=math.floor(ausiliar_rules[x][0]/15)\n",
    "    ord=ausiliar_rules[x][0] % 15\n",
    "    #If the rule_position is not already included in the final_rules, we will include it\n",
    "    if environment[axi][ord]!=42:\n",
    "        environment[axi][ord]=42\n",
    "        final_rules.append(ausiliar_rules[x])\n",
    "\n",
    "#Print the final rules generated        \n",
    "print(\"The number of final rules generated is:\")\n",
    "print(len(final_rules))\n",
    "print(\"Print the room, so that the positions for which a rule is defined are marked with an *:\")\n",
    "print_room(environment)    \n",
    "print(\"Print the final rules that agent must use to complete the task:\")\n",
    "print(final_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the Task "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating our rules through the genetic algorithm we can finally move on to solve the task. The idea for doing this is very simple. We start with the agent in the random position given by the MiniHack env.reset() command. After that, at each step, the agent performs one of the following actions:\n",
    "\n",
    "- if a rule exists at the position it is in, it moves according to the rule's instructions.\n",
    "\n",
    "- otherwise, it moves randomly with uniform probability. \n",
    "\n",
    "To check if there is a rule at the position where the agent is, I help myself with the environment matrix created earlier. If the task is completed in a low number of moves, it means that our genetic algorithm has worked well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a counter for the number of moves of the agent.\n",
    "cont=1\n",
    "\n",
    "while agent_position_1!=goal_1 or agent_position_2!=goal_2:\n",
    "        \n",
    "    print(\"Iteration Number\", cont)\n",
    "    #transform the positions from indexes to sequence of integers\n",
    "    ag_position=agent_position_1*15+agent_position_2\n",
    "    \n",
    "    #check if there is a rule in the agent position     \n",
    "    if environment[agent_position_1][agent_position_2]==42:\n",
    "        \n",
    "        #look for the rule in the final_rules list and update agent position\n",
    "        for x in range(len(final_rules)):\n",
    "            if final_rules[x][0]==ag_position:\n",
    "\n",
    "                old_position = [agent_position_1, agent_position_2]\n",
    "                \n",
    "                agent_position_1, agent_position_2 = update_position(old_position, final_rules[x][1])\n",
    "                \n",
    "                #print the information about the movement\n",
    "                print(\"We use the rule\", x, \" and we move to\", agent_position_1, \",\", agent_position_2, end=\" \")\n",
    "                print(\"using the action\", movement_dictionary[final_rules[x][1]])\n",
    "                \n",
    "                #move the agent with the MiniHack's command env.step()\n",
    "                env.step(final_rules[x][1])\n",
    "                #update the variable x to exit the for loop \n",
    "                x=10000\n",
    "\n",
    "    #randomly move the agent if there is no rule for its position\n",
    "    elif environment[agent_position_1][agent_position_2]!=42:\n",
    "        \n",
    "        #create random movement\n",
    "        mov=random.choice(range(0, 8))   \n",
    "        \n",
    "        old_position = [agent_position_1, agent_position_2]\n",
    "        \n",
    "        agent_position_1, agent_position_2 = update_position(old_position, mov)\n",
    "\n",
    "        #check that the random move does not come out of the matrix\n",
    "        while agent_position_1<0 or agent_position_1>=15 or agent_position_2<0 or agent_position_2>=15:\n",
    "            \n",
    "            #create a new random movement\n",
    "            agent_position_1=math.floor(ag_position/15)\n",
    "            agent_position_2=ag_position % 15\n",
    "            mov = random.choice(range(0, 8))\n",
    "            \n",
    "            old_position = [agent_position_1, agent_position_2]\n",
    "        \n",
    "            agent_position_1, agent_position_2 = update_position(old_position, mov)\n",
    "\n",
    "        #move the agent with the MiniHack's command env.step()\n",
    "        env.step(mov)\n",
    "        #print the information about the movement\n",
    "        print(\"We use the random movement\", movement_dictionary[mov], \" and we move to\", agent_position_1, \",\", agent_position_2)\n",
    "    \n",
    "    #print room to see the new agent position    \n",
    "    print_room(obs['chars'][i:i+15, j:j+15])\n",
    "    #print if the task is completed    \n",
    "    if agent_position_1==goal_1 and agent_position_2==goal_2:\n",
    "        print(\"Task Completed in\", cont, \"moves!!!!!\")\n",
    "    else:          \n",
    "        print(\"###########################################################\")\n",
    "    #update the counter\n",
    "    cont=cont+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minihack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "225342802ed85a0002a561b5e0fd78264fe9258752f7875914e1d010453066c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
