import gym
import minihack
import numpy as np
from typing import List
import random
import math
import pygad
from operator import itemgetter

#global GOAL_1, GOAL_2

movement_dictionary = {
    0 : "north",
    1 : "east",
    2 : "south",
    3 : "west",
}

class Rule:
    '''
    The class Rule generates a couple (position, movement)
    Each rule represents an individual (state) of the population of our genetic algorithm
    '''

    
    #The position of the agent in the 15x15 room (an np.ndarray)
    position: List[int] = [0, 0]

    movement: int
    # movement: {'north': 0, 'east': 1, 'south': 2, 'west': 3} 
    
    def __init__(self):
        '''
        Initiliaze a random position and random movement
        index_matrix represent the start position of the 15x15 room when is represented by a 21x79 matrix 
        '''

        self.position[0] = random.choice(range(0, 15))
        self.position[1] = random.choice(range(0, 15))
        

        #Move randomly in any direction
        self.movement = random.choice(range(0, 4))
        
        #check that the rule is well defined
        before_pos_1=self.position[0]
        before_pos_2=self.position[1]

        old_position=[before_pos_1, before_pos_2]
        before_pos_1, before_pos_2 = update_position(old_position, self.movement)

        #if self.movement==0 : 
        #    before_pos_1=before_pos_1-1 #movement to norh
        #elif self.movement==1 :
        #    before_pos_2=before_pos_2+1 #movement to east
        #elif self.movement==2 :
        #    before_pos_1=before_pos_1+1 #movement to sud
        #elif self.movement==3:
        #    before_pos_2=before_pos_2-1 #movement to west
        
        #while before_pos_1<0 or before_pos_1>=15 or before_pos_2<0 or before_pos_2>=15:
        while (not is_legal_move(old_position, self.movement)):
               
            print("\n RIP! Previous movement =", movement_dictionary[self.movement], "\n")
            
            self.movement = random.choice(range(0, 4))
            before_pos_1=self.position[0]
            before_pos_2=self.position[1]

            old_position=[before_pos_1, before_pos_2]
            before_pos_1, before_pos_2 = update_position(old_position, self.movement)
            
            #if self.movement==0 : 
            #    before_pos_1=before_pos_1-1 #movement to norh
            #elif self.movement==1 :
            #    before_pos_2=before_pos_2+1 #movement to east
            #elif self.movement==2 :
            #    before_pos_1=before_pos_1+1 #movement to sud
            #elif self.movement==3:
            #    before_pos_2=before_pos_2-1 #movement to west

        
    def rule_list(self):
        return [self.position[0]*15+self.position[1], self.movement]

def is_legal_move(old_position: List[int], movement: int) -> bool:
    """ Check if the agent is moving in a legal position """

    if movement == 0: #north
        if old_position[0] == 0:
            return False
    elif movement == 1: #east
        if old_position[1] == 14:
            return False
    elif movement == 2: #south
        if old_position[0] == 14:
            return False
    elif movement == 3: #west
        if old_position[1] == 0:
            return False
        
    return True
        
def update_position(old_position: List[int], movement: int) -> List[int]:
    """ Return updated positions of the agent in the environment         

        old_position is a legal move
        movement: int 0..3 indication of direction
    """
    
    # Directions store the movements possible, if you want to move diagonally you can add more directions here
    directions = [(0, -1), (1, 0), (0, 1), (-1, 0)] 
    
    new_position = [-1, -1]
    
    update_position = directions[movement]
    
    new_position[0] = old_position[0] + update_position[0]
    new_position[1] = old_position[1] + update_position[1]

    return new_position[0], new_position[1] 

def print_room(environment):
    """
    Print the room in ASCII characters. 
    Note that the matrix is equal to the random room generated by MiniHack
    """

    for row in range(len(environment[:,1])):
        for col in range(len(environment[1,:])):
            print(chr(environment[row][col]), end=' ') 
        print('\n')

def search_environment_indexes(environment):
    """ 
    Searching enviroment indexes, usually are the same, 
    maybe we can calculate theme once and them use as a costant
    if change for each different room maybe this will be useful then
    """
    
    i=j=temp=0

    #Find the indexes [x,y] from which to start extracting the submatrix
    for row in range(len(environment[:,1])):
        for col in range(len(environment[1,:])):
            if temp == 0 and int(environment[row][col]) != 32:
                i = row
                j = col
                temp=1
    return i,j      

def search_environment_agent_position(environment: np.ndarray):
    """ Return agent position inside the environment """
    
    for row in range(len(environment[:,1])):
        for col in range(len(environment[1,:])):
            if int(environment[row][col]) == 64:
                return row, col

def search_environment_goal_position(environment: np.ndarray):
    """ Return staircase position inside the environment """
    
    for row in range(len(environment[:,1])):
        for col in range(len(environment[1,:])):
            if int(environment[row][col]) == 62:
                global GOAL_1, GOAL_2
                GOAL_1=row
                GOAL_2=col
                return row, col


def fitness_function(solution, solution_idx):
    '''
    fitness function for the importance of every rules
    solution is a triple of int in which:
    solution[0]= agent position in a rule, calculated as 15*agent position in row + agent position in column
    solution[1]= agent movement
    solution[2]= agent action #FIXME maybe this is not necessary anymore
    '''
    
    ag_pos_before_rule_1=math.floor(solution[0]/15)
    ag_pos_before_rule_2=solution[0] % 15

    #check that the generated rule is not the goal position
    if ag_pos_before_rule_1==GOAL_1 and ag_pos_before_rule_2==GOAL_2:
       print("We have Goal Position")
       return 0
    
    #define the new agent position after applying the action in solution[2]
    ag_pos_after_rule_1=ag_pos_before_rule_1 
    ag_pos_after_rule_2=ag_pos_before_rule_2

    #FIXME Debug flag for changing executing code
    VINCENT_CODE = False
    
    if not VINCENT_CODE:

        if solution[1]==0 : 
            ag_pos_after_rule_1=ag_pos_after_rule_1-1 #movement to norh
        elif solution[1]==1 :
            ag_pos_after_rule_2=ag_pos_after_rule_2+1 #movement to east
        elif solution[1]==2 :
            ag_pos_after_rule_1=ag_pos_after_rule_1+1 #movement to sud
        elif solution[1]==3:
            ag_pos_after_rule_2=ag_pos_after_rule_2-1 #movement to west
      
        #if not is_legal_move(new_position, solution[1]):
        #    return 0

        if ag_pos_after_rule_1<0 or ag_pos_after_rule_1>=15 or ag_pos_after_rule_2<0 or ag_pos_after_rule_2>=15:
            return 0
    else:
    #new_position = [ag_pos_before_rule_1, ag_pos_before_rule_2]
        new_position = [ag_pos_after_rule_1, ag_pos_after_rule_2]

        #If rule is not legal (get out of map), return 0 as fitness
    
        ag_pos_after_rule_1, ag_pos_after_rule_2 = update_position(new_position, solution[1])    

        if not is_legal_move(new_position, solution[1]):
            return 0

    #print("Goal position:2", GOAL_1, ", ", GOAL_2)
    #print("Agent position before rule:", ag_pos_before_rule_1, ",", ag_pos_before_rule_2, "; move:", movement_dictionary[solution[1]])
    #print("Agent position after rule:", ag_pos_after_rule_1, ",",  ag_pos_after_rule_2)

    distance_before=np.abs(ag_pos_before_rule_1-GOAL_1)+np.abs(ag_pos_before_rule_2-GOAL_2)
    distance_after=np.abs(ag_pos_after_rule_1-GOAL_1)+np.abs(ag_pos_after_rule_2-GOAL_2)

    #print("Distance before and after:", distance_before, ",", distance_after, "Diff:", distance_before-distance_after)
    
    auxiliar=(distance_before-distance_after)/(math.sqrt(distance_before))
    fitness=50*auxiliar+50

    #print("Fitness value:", fitness)

    return fitness

def cross_func(istance, parents) :
    print(parents)


def information_matrix(population, fitness_value, best_solution) :
    #Print some information about the quality of genetic algorithm

    environment=np.full((15, 15), 46, dtype=int)
    environment[GOAL_1][GOAL_2]=62

    rules_ausiliar=[]
    rules_ausiliar.append([best_solution[0], best_solution[1], fitness_value[0]])

    for x in range(len(population)) :
        rules_ausiliar.append([population[x][0], population[x][1], fitness_value[x+1]])
    
    #print(rules) 

    rules_ausiliar=sorted(rules_ausiliar, key=itemgetter(2), reverse=True)
    rules_ausiliar=sorted(rules_ausiliar, key=itemgetter(0))
    rules=[]
    for x in range(len(rules_ausiliar)) :
        axi=math.floor(rules_ausiliar[x][0]/15)
        ord=rules_ausiliar[x][0] % 15
        if environment[axi][ord]!=42 and rules_ausiliar[x][2]!=0:
            environment[axi][ord]=42
            rules.append(rules_ausiliar[x])
    
    #print("###############################")
    #print(rules)
    #print_room(environment)
    #print(len(rules))
    
    return rules, environment

    
def main():
    #Generate a Room-15x15 task
    env=gym.make(
        "MiniHack-Room-Random-15x15-v0",
        observation_keys=("chars", "colors", "specials", "pixel"),
)

    obs = env.reset() #Generate a new environment and save the describtions arrays in obs
    env.render() #Print the room 
    #
    #obs contains the "glyphs","chars",...,"pixel" arrays which describe the room
    #See documentation for information on arrays
    i,j = search_environment_indexes(obs['chars'])

    #print(i, " ", j)
    print("Tha matrix in ASCII that represent the random room is:")
    print_room(obs['chars'][i:i+15, j:j+15])
    
    
    agent_position_1, agent_position_2 = search_environment_agent_position(obs['chars'][i:i+15, j:j+15])
    goal_1, goal_2 = search_environment_goal_position(obs['chars'][i:i+15, j:j+15])
    
    print("The goal position is: ", goal_1, " ", goal_2)
    print("The agent position is: ", agent_position_1, " ",  agent_position_2)
    
    list_of_rules=[]
    for x in range(1000):
        rule=Rule()
        list_of_rules.append(rule.rule_list())
        print("The", x+1, "-th rules is:")
        print("Position: (", math.floor(list_of_rules[x][0]/15), ", ", list_of_rules[x][0] % 15, ") =", list_of_rules[x][0])
        print("Movement: ", list_of_rules[x][1], " - ", movement_dictionary[list_of_rules[x][1]])
        
        """
        Define list_of_rules as a list of lists, in which every element of the main list is
        defined as triple of int [x_1, x_2, x_3] that are associated a one object, and in 
        particular we have:
        -x_1 is the agent_position_1 * 15 + agent_position_2
        -x_3 is the agent movement
        
        We can not define list_of_rules as a list of object because of definitio of pygad library 
        """
    #fit=fitness_function(list_of_rules[99], 2)

    print("First generation of rules:")
    for rule in list_of_rules:
        print("\n", rule)

    print("####################################")

    fitness_func = fitness_function
    cross=cross_func
    
    ga_instance = pygad.GA(fitness_func=fitness_func,
                           initial_population=list_of_rules,
                           gene_type=int,
                           num_generations=5,
                           num_parents_mating=1000,
                           parent_selection_type="rws",
                           crossover_probability=1.0,
                           crossover_type="single_point",
                           #on_parents=cross,
                           mutation_type= None)

    ga_instance.run()

    fitness_value, population=ga_instance.last_generation_fitness, ga_instance.last_generation_offspring_mutation
    best_solution=ga_instance.best_solution()[0]
    
    print(ga_instance.best_solution())
    print(ga_instance.best_solution()[0])
    print(population)
    print(fitness_value)

    rules, environment = information_matrix(population, fitness_value, best_solution)

    #ga_instance.plot_fitness()
    #ga_instance.plot_genes()

    #population=sorted(population, key=itemgetter(0))
    #print(population)

    print("###############################")
    print(rules)
    print_room(environment)
    print(len(rules))
    print_room(obs['chars'][i:i+15, j:j+15])

    cont=0

    while agent_position_1!=GOAL_1 or agent_position_2!=GOAL_2:
        
        print("ITERATION NUMBER", cont)
        ag_position=agent_position_1*15+agent_position_2
        
        if environment[agent_position_1][agent_position_2]==42:

            for x in range(len(rules)):
                if rules[x][0]==ag_position:
                    #update_position(ag_position, rules[x][1]) 
                    if rules[x][1]==0 : 
                        agent_position_1=agent_position_1-1 #movement to norh
                    elif rules[x][1]==1 :
                        agent_position_2=agent_position_2+1 #movement to east
                    elif rules[x][1]==2 :
                        agent_position_1=agent_position_1+1 #movement to sud
                    elif rules[x][1]==3:
                        agent_position_2=agent_position_2-1 #movement to west

                    print("We use the rule", x, " and we move to", agent_position_1, ",", agent_position_2, end=" ")
                    print("using the action", movement_dictionary[rules[x][1]])

                    if agent_position_1==GOAL_1 and agent_position_2==GOAL_2:
                        print("TASK COMPLETED!!!!!")

                    env.step(rules[x][1])
                    x=10000

        elif environment[agent_position_1][agent_position_2]!=42:
            mov=random.choice(range(0, 4))   
            if mov==0 : 
                agent_position_1=agent_position_1-1 #movement to norh
            elif mov==1 :
                agent_position_2=agent_position_2+1 #movement to east
            elif mov==2 :
                agent_position_1=agent_position_1+1 #movement to sud
            elif mov==3:
                agent_position_2=agent_position_2-1 #movement to west
            
            while agent_position_1<0 or agent_position_1>=15 or agent_position_2<0 or agent_position_2>=15:

                agent_position_1=math.floor(ag_position/15)
                agent_position_2=ag_position % 15
                mov = random.choice(range(0, 4))
                if mov==0 : 
                    agent_position_1=agent_position_1-1 #movement to norh
                elif mov==1 :
                    agent_position_2=agent_position_2+1 #movement to east
                elif mov==2 :
                    agent_position_1=agent_position_1+1 #movement to sud
                elif mov==3:
                    agent_position_2=agent_position_2-1 #movement to west


            print("We use the random movement", movement_dictionary[mov], " and we move to", agent_position_1, ",", agent_position_2)

            if agent_position_1==GOAL_1 and agent_position_2==GOAL_2:
                print("TASK COMPLETED!!!!!")

            env.step(mov)
        
        print_room(obs['chars'][i:i+15, j:j+15])  
        print("###########################################################")
        cont=cont+1


if __name__ == "__main__":
    main()
